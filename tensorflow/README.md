# PaddlePaddle Fluid å’Œ TensorFlow å¹¶è¡Œç‰¹æ€§å¯¹æ¯”

parallel computation | Fluid | Tensorflow
-- | -- | --
multiple devices | ParallelExecutor | parameter_server/replica
multiple nodes   | parameter_server/ring-base | distributed_replica/parameter_server/Horvod

## å¤šè®¾å¤‡

### TensorFlow

TensorFlow æ”¯æŒ `parameter_server` å’Œ `replica` ä¸¤ç§æ–¹å¼è¿›è¡Œå¤šå¡çš„è®­ç»ƒ:

1. åœ¨ `parameter_server` æ¨¡å¼ä¸­:
    - è®­ç»ƒè¿›ç¨‹ä¸­ä¼šä¿å­˜ä¸€ä»½ä¸»å‚æ•°ï¼Œé€šå¸¸æ˜¯CPU Memoryã€‚
    - æ¯ä¸ªè®¾å¤‡ç§°ä¸ºä¸€ä¸ª `worker`, æ¯ä¸ªworkeréƒ½ä¿å­˜æœ‰ä¸€ä¸ªæ¨¡å‹å‰¯æœ¬ï¼Œåœ¨è®¡ç®—æ—¶ä¼šæ ¹æ®ä¾èµ–å…³ç³»ä» `parameter_server` ä¸­æ‹‰æ‹‰å–éœ€è¦çš„å‚æ•°å¹¶åšåç»­çš„è®¡ç®—ã€‚
    - æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥è®­ç»ƒ.

1. åœ¨ `replica` æ¨¡å¼ä¸­:
    - æ¯ä¸ªè®¾å¤‡æ‹¥æœ‰ä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹å‰¯æœ¬ä»¥åŠå‚æ•°çš„æ‹·è´ã€‚
    - æ¯ä¸ªè®¾å¤‡ç‹¬ç«‹è®¡ç®— gradientåï¼Œä½¿ç”¨ `Reduce/Broadcast` æ¥èšåˆ/åŒæ­¥æœ€æ–°çš„å‚æ•°åŒæ­¥åˆ°æ‰€æœ‰çš„è®¾å¤‡ä¸Šã€‚
    - æ”¯æŒåŒæ­¥è®­ç»ƒã€‚

### Fluid

Fluid ä¸­ä½¿ç”¨ `ParallelExecutor` æ”¯æŒå¤šå¡çš„å¹¶è¡Œè®­ç»ƒ:
- `SSAGraph Builder` å°†ç”¨æˆ·é…ç½®çš„ ProgramDesc è½¬æ¢æˆä¸€ä¸ªä¾èµ–å›¾ `SSAGraph`.
- `ParallelExecutor` ä¼šæ ¹æ®opçš„ä¾èµ–å…³ç³»å¹¶è¡Œçš„æ‰§è¡Œæ‰€æœ‰opã€‚
- å’Œ TensorFlow ä¸­ `replica` æ¨¡å¼é‡‡å–ä¸€æ ·çš„ç­–ç•¥æ›´æ–°å‚æ•°ï¼Œå¹¶ä¸”åœ¨èšåˆå‚æ•°æ—¶ä½¿ç”¨ NCCL2çš„ `Reduce/AllReduce` æ¥
èšåˆå‚æ•°ï¼Œ åœ¨å¤§éƒ¨åˆ†åœºæ™¯ä¸‹ `Reduce` æ€§èƒ½ä¼šå¥½ä¸€äº›ã€‚

## å¤šèŠ‚ç‚¹

### TensorFlow

1. parameter_server
    - è®­ç»ƒèŠ‚ç‚¹åˆ†ä¸º `worker`, `ps` ä¸¤ç§è§’è‰²ï¼Œps ä¸­ä¿å­˜äº†å‚æ•°çš„ master å‰¯æœ¬ã€‚
    - worker èŠ‚ç‚¹åœ¨è®­ç»ƒæ—¶ä¼šæ ¹æ®ä¾èµ–å…³ç³»ä» ps ä¸­æ‹‰å–æœ€æ–°çš„å‚æ•°è¿›è¡Œè®¡ç®—ã€‚
    - æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥è®­ç»ƒã€‚
1. distribute_replica
    - è®­ç»ƒèŠ‚ç‚¹åˆ†ä¸º `worker`,  `ps` ä¸¤ç§è§’è‰²ï¼Œä½† ps å¹¶ä¸ä¿å­˜ master å‰¯æœ¬ã€‚
    - æ¯ä¸ª worker èŠ‚ç‚¹éƒ½ä¿å­˜ä¸€ä»½å®Œæ•´çš„å‚æ•°æ‹·è´ï¼Œå¹¶å°†è®¡ç®—å‡ºçš„ gradient å‘é€åˆ° ps èŠ‚ç‚¹è¿›è¡Œæ›´æ–°ï¼Œç„¶åå†å°†æœ€æ–°çš„å‚æ•°åŒæ­¥å› worker èŠ‚ç‚¹ã€‚
    - æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥è®­ç»ƒã€‚
1. Horovrd
    - æ—  `ps` èŠ‚ç‚¹ï¼Œæ‰€æœ‰å‚æ•°å‡ä¿å­˜åœ¨ `worker` èŠ‚ç‚¹ä¸­ã€‚
    - æ¯ä¸ª worker èŠ‚ç‚¹å ç”¨ä¸€ä¸ª GPU è®¾å¤‡, æ‰€æœ‰ worker èŠ‚ç‚¹ç»„æˆ Ring ç»“æ„ã€‚
    - æ”¯æŒåŒæ­¥è®­ç»ƒã€‚

### Fluid

1. parameter_server
    - è®­ç»ƒèŠ‚ç‚¹åˆ†ä¸º `trainer`, `ps` ä¸¤ç§è§’è‰²ã€‚
    - trainer èŠ‚ç‚¹ä¿å­˜å®Œæ•´çš„å‚æ•°å‰¯æœ¬å¹¶è®¡ç®— gradï¼Œ ps è´Ÿè´£å‚æ•°æ›´æ–°ã€‚
    - æ”¯æŒåŒæ­¥ï¼Œå¼‚æ­¥è®­ç»ƒã€‚
    - trainer èŠ‚ç‚¹æ”¯æŒ prefetch çš„æ–¹å¼ä» pserver æ‹‰å–æŸä¸€æŒ‡å®šå‚æ•°ã€‚
1. ring-base
    - æ—  `ps` èŠ‚ç‚¹ï¼Œtrainer èŠ‚ç‚¹ä¿å­˜æ‰€æœ‰çš„å‚æ•°æ‹·è´ã€‚
    - ä½¿ç”¨ NCCL2 çš„ Reduce/AllReduce/BroadCast å®ç°å¤šGPUå¤šèŠ‚ç‚¹ä¹‹é—´çš„å‚æ•°èšåˆå’ŒåŒæ­¥ã€‚
    - åªæ”¯æŒGPUçš„åŒæ­¥è®­ç»ƒã€‚
 
## Reference

- https://www.tensorflow.org/performance/performance_models
- https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks
- https://github.com/uber/horovod